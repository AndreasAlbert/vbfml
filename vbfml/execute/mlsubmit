#!/usr/bin/env python3

import argparse
import os

from datetime import datetime

from vbfml.util import vbfml_path, git_rev_parse, git_diff
from vbfml.helpers.deployment import pack_repo
from vbfml.helpers.condor import condor_submit

pjoin = os.path.join

def parse_cli():
    parser = argparse.ArgumentParser()
    parser.add_argument('training_directory', help='Path to the directory where the sequences and the model is saved.')
    parser.add_argument('--jobname', default=None, help='Job name specifying this particular submission.')
    parser.add_argument('--overwrite', type=bool, default=False, help='If a submission directory exists, whether to overwrite. Defaults to False.')
    parser.add_argument('--jobs', type=int, default=2, help='Number of cores to request.')
    parser.add_argument('--memory', type=int, default=None, help='Maximum amount of memory to request.')
    parser.add_argument('--dry', action='store_true', help='Dry run flag.')
    parser.add_argument('--steps_per_epoch', type=int, default=int(1e3), help='Number of batches in an epoch.')
    parser.add_argument('--training_passes', type=int, default=10, help='Number of iterations through the whole training set.')
    args = parser.parse_args()
    return args

def do_submit(args):
    '''Submission operation.'''
    import htcondor
    # Create the submission directory
    if args.jobname:
        subdir = os.path.abspath(pjoin("./submission", args.jobname))
        if os.path.exists(subdir) and not args.overwrite:
            raise RuntimeError(f"Will not use existing submission directory unless --overwrite is specified: {subdir}")
    else:
        timetag = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        subdir = os.path.abspath(pjoin("./submission", timetag))
    
    if not os.path.exists(subdir):
        os.makedirs(subdir)

    # Repo version information
    with open(pjoin(subdir, 'version.txt'),'w') as f:
        f.write(git_rev_parse()+'\n')
        f.write(git_diff()+'\n')

    # List of input files/directories we want to ship to the execution machine
    input_files = []

    # Pack the repository for deployment to execution machine
    gridpack_path = pjoin(subdir, 'vbfml.tgz')
    if not os.path.exists(gridpack_path) or args.overwrite:
        pack_repo(gridpack_path, args.training_directory, overwrite=args.overwrite)
    
    input_files.append(gridpack_path)

    # Submission details!
    filedir = pjoin(subdir, "files")
    if not os.path.exists(filedir):
        os.makedirs(filedir)

    # Arguments to the shell script
    arguments = [
        f'--tag {os.path.basename(args.training_directory)}',
        'train',
        f'--steps-per-epoch {args.steps_per_epoch}',
        f'--training-passes {args.training_passes}',
    ]

    submission_settings = {
        "Initialdir" : subdir,
        "executable" : vbfml_path("execute/htcondor_wrap.sh"),
        "arguments" : " ".join(arguments),
        "should_transfer_files" : "YES",
        "when_to_transfer_output" : "ON_EXIT",
        "transfer_input_files" : ", ".join(input_files),
        "Output" : pjoin(filedir, "out.txt"),
        "Error" : pjoin(filedir, "err.txt"),
        "log" : pjoin(filedir, "log.txt"),
        # "request_cpus" : str(args.jobs),
        "request_memory" : str(args.memory if args.memory else 2500),
        # "+MaxRuntime" : f"{60*60*12}",
        "on_exit_remove" : "((ExitBySignal == False) && (ExitCode == 0)) || (NumJobStarts >= 2)",
        "request_GPUs" : 1,
    }

    # Prepare the jdl job file
    sub = htcondor.Submit(submission_settings)
    jdl = pjoin(filedir,'job_file.jdl')
    with open(jdl, 'w') as f:
        f.write(str(sub))
        f.write("\nqueue 1\n")

    # Go ahead with the submission
    if args.dry:
        print('Dry run completed.')
    else:
        jobid = condor_submit(jdl)
        print(f'Submitted job ID: {jobid}')

def main():
    args = parse_cli()
    do_submit(args)

if __name__ == '__main__':
    main()