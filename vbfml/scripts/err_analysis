#!/usr/bin/env python3
import copy
import os
import re
import warnings
import click
import pickle

import tensorflow as tf
import numpy as np
import pandas as pd

from tqdm import tqdm
from glob import glob
from matplotlib import pyplot as plt
from typing import Tuple

from vbfml.util import get_process_tag_from_file
from vbfml.plot.util import Quantity
from vbfml.training.util import summarize_datasets, select_and_label_datasets
from vbfml.training.data import TrainingLoader
from vbfml.training.plot import ImagePlotter
from vbfml.training.input import build_sequence, load_datasets_bucoffea

warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)

pjoin = os.path.join


def gather_data(input_dir: str) -> Tuple:
    """
    Load data from pickle caches and return.
    """
    with open(pjoin(input_dir, "df_non_feature.pkl"), "rb") as f:
        df = pickle.load(f)

    with open(pjoin(input_dir, "predictions.pkl"), "rb") as f:
        predictions = pickle.load(f)

    return df, predictions


@click.group()
def cli():
    pass


@cli.command()
@click.pass_context
@click.option(
    "-i",
    "--input-files",
    required=True,
    help="Path to the directory with the input ROOT files.",
)
@click.option(
    "-m",
    "--model-path",
    required=True,
    help="Path to the model directory.",
)
@click.option(
    "-t",
    "--tag",
    required=True,
    help="Tag to identify the process.",
)
def predict(ctx, input_files: str, model_path: str, tag: str) -> None:
    """
    Read events from the input_files, make predictions
    with the pre-trained model (read from model_path) and save the
    predictions, together with other event data for later use.

    input_files can be either a single file, or can contain an asterisk (*)
    to specify multiple files.
    """
    # Create a list of DatasetInfo objects for the files that we are interested in
    directory, file_pattern = os.path.dirname(input_files), os.path.basename(
        input_files
    )
    datasets = load_datasets_bucoffea(directory, file_pattern)
    dataset_labels = {
        "ewk_17": "(EWK.*2017|VBF_HToInvisible_M125_withDipoleRecoil_pow_pythia8_2017)",
        "v_qcd_nlo_17": "(WJetsToLNu_Pt-\d+To.*|Z\dJetsToNuNu_M-50_LHEFilterPtZ-\d+To\d+)_MatchEWPDG20-amcatnloFXFX_2017",
    }
    datasets = select_and_label_datasets(datasets, dataset_labels)
    summarize_datasets(datasets)

    high_level_features = [
        "mjj",
        "detajj",
        "njet",
        "recoil_pt",
        "recoil_phi",
        "leadak4_pt",
        "trailak4_pt",
        "leadak4_eta",
        "trailak4_eta",
        "leadak4_phi",
        "trailak4_phi",
    ]

    image_features = ["JetImage_pixels"]

    # Validation sequence: Read the last 20% of events
    read_range = (0.8, 1.0)

    # Two separate validation sequences for high_level features (e.g. mjj) and image features:
    # We'll make the predictions based on the image features, but we'll plot the
    # high-level quantities at the end
    validation_sequences = {}

    validation_sequences["high_level"] = build_sequence(
        datasets=copy.deepcopy(datasets),
        features=high_level_features,
        weight_expression="weight_total*xs/sumw",
        shuffle=True,
        scale_features="none",
    )
    validation_sequences["high_level"].batch_size = int(1e6)
    validation_sequences["high_level"].batch_buffer_size = 1

    validation_sequences["image"] = build_sequence(
        datasets=copy.deepcopy(datasets),
        features=image_features,
        weight_expression="weight_total*xs/sumw",
        shuffle=True,
        scale_features="norm",
    )

    validation_sequences["image"].batch_size = int(1e3)
    validation_sequences["image"].batch_buffer_size = 10

    for sequence in validation_sequences.values():
        sequence.read_range = read_range

    # Load the pre-trained model
    loader = TrainingLoader(model_path)
    model = loader.get_model()

    predictions = []
    image_pixels = []
    for ibatch in tqdm(
        range(len(validation_sequences["image"])), desc="Making predictions"
    ):
        features, _, _ = validation_sequences["image"][ibatch]
        predictions.append(model.predict(features).argmax(axis=1))
        image_pixels.append(features)

    predictions = np.concatenate(predictions)
    image_pixels = np.concatenate(image_pixels)

    # High-level features
    features = {f: [] for f in high_level_features}
    for ibatch in tqdm(
        range(len(validation_sequences["high_level"])),
        desc="Obtaining high-level features",
    ):
        # Fill the sequence buffer if the batch is not there
        validation_sequences["high_level"][ibatch]
        df_non_feature = validation_sequences["high_level"].buffer.get_batch_df(ibatch)
        df_non_feature.drop(columns=["label"], inplace=True)

    outdir = pjoin(model_path, f"predictions_{tag.lower()}")
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    # Dump the input file argument to a txt file
    input_list_file = pjoin(outdir, "input_root_files.txt")
    with open(input_list_file, "w+") as f:
        for infile in glob(input_files):
            f.write(f"{infile}\n")

    # Save dataframe with high-level features (e.g. mjj)
    df_cache = pjoin(outdir, "df_non_feature.pkl")
    with open(df_cache, "wb+") as f:
        pickle.dump(df_non_feature, f)

    # Save the predictions into a pkl file
    cache = pjoin(outdir, "predictions.pkl")
    with open(cache, "wb+") as f:
        pickle.dump(predictions, f)

    # Also save the image arrays for later use
    images_cache = pjoin(outdir, "images.pkl")
    with open(images_cache, "wb+") as f:
        pickle.dump(image_pixels, f)


@cli.command()
@click.pass_context
@click.argument("input_dir")
def plot(ctx, input_dir: str) -> None:
    """
    Make histogram of high-level features, split by the predicted class,
    and plot the histograms.
    """
    # Gather the data
    df, predictions = gather_data(input_dir)

    process_tag = os.path.basename(input_dir.rstrip("/")).replace("predictions_", "")

    outdir = pjoin(input_dir, "plots")
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    # Based on the predictions, we make histograms for different classes
    quantities = [x for x in list(df.columns) if x != "weight"]

    for quantity_name in tqdm(
        quantities, desc="Plotting histograms"
    ):
        quantity = Quantity(quantity_name)
        fig, ax = plt.subplots()
        for icls, sample_cls in enumerate(["ewk_17", "v_nlo_qcd_17"]):
            mask = predictions == icls
            ax.hist(
                df[quantity_name][mask],
                histtype="step",
                weights=df["weight"][mask],
                bins=quantity.bins,
                label=sample_cls,
            )

        ax.set_xlabel(quantity.label, fontsize=14)
        ax.set_ylabel("Weighted Counts", fontsize=14)

        ax.set_yscale('log')

        ax.legend(title="Predicted Class")

        ax.text(
            1,
            1,
            f"# Events: {len(predictions)}",
            fontsize=14,
            ha="right",
            va="bottom",
            transform=ax.transAxes,
        )
        ax.text(
            0,
            1,
            process_tag,
            fontsize=14,
            ha="left",
            va="bottom",
            transform=ax.transAxes,
        )

        outpath = pjoin(outdir, f"{quantity_name}.pdf")
        fig.savefig(outpath)
        plt.close(fig)


@cli.command()
@click.pass_context
@click.argument("input_dir")
@click.option(
    "-q", "--quantity", required=True, help="The quantity to compute the threshold."
)
@click.option(
    "-t", "--threshold", type=float, required=True, help="The threshold value."
)
def average(ctx, input_dir: str, quantity: str, threshold: float) -> None:
    """
    Given the set of predictions and the high-level features (e.g. mjj),
    compute the average image per class (QCD V / EWK V) for events that
    satisfy:

    quantity > threshold.
    """
    # Gather the data
    df, predictions = gather_data(input_dir)

    with open(pjoin(input_dir, "input_root_files.txt"), "r") as f:
        inputfile = f.readlines()[0]

    process_tag = get_process_tag_from_file(inputfile)

    outdir = pjoin(input_dir, "averaged")
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    plotter = ImagePlotter()

    # Load the images
    with open(pjoin(input_dir, "images.pkl"), "rb") as f:
        image_pixels = pickle.load(f)

    # Get the images for the events where quantity > threshold
    # and compute the average for these images.
    mask = df[quantity] > threshold
    classes = ["ewk_17", "v_nlo_qcd_17"]
    for iclass, class_label in enumerate(
        tqdm(classes, desc="Plotting averaged images")
    ):
        image_mask = mask & (predictions == iclass)
        images = image_pixels[image_mask]
        weights = df["weight"][image_mask]

        avg_image = np.average(images, axis=0, weights=weights)
        outdir = pjoin(input_dir, "plots")

        plotter.plot(
            image=avg_image,
            outdir=outdir,
            filename=f"{class_label}_{quantity}_gt_{threshold}.pdf",
            cbar_label="Average Energy (GeV)",
            left_label=process_tag,
            right_label=class_label,
        )


@cli.command()
@click.pass_context
@click.argument("input_dir")
@click.option(
    "-s",
    "--sequence-type",
    required=False,
    default="validation",
    help="The type of sequence: training or validation.",
)
def evaluate(ctx, input_dir: str, sequence_type: str) -> None:
    """
    Evalute the accuracy of the pre-trained model on full sequence.
    """
    loader = TrainingLoader(input_dir)

    model = loader.get_model()
    sequence = loader.get_sequence(sequence_type)

    sequence.batch_size = int(1e3)
    sequence.batch_buffer_size = 100

    model.evaluate(sequence)


if __name__ == "__main__":
    cli()
